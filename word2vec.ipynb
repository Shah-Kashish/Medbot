{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f8c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kashish\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer=LancasterStemmer()\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import glorot_uniform\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import json\n",
    "import gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659d30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Kashish\\Desktop\\GU SEM 7 PROJECT PROPOSAL\\Medical-Chatbot-master\\Medbot_DataSet.json\",'r',encoding='UTF-8') as file:\n",
    "    data=json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76febea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load(r\"C:\\Users\\Kashish\\Desktop\\GU SEM 7 PROJECT PROPOSAL\\Medical-Chatbot-master\\Medbot_Words.bin\")\n",
    "except:\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        r\"C:\\Users\\Kashish\\Desktop\\GU SEM 7 PROJECT PROPOSAL\\Medical-Chatbot-master\\GoogleNews-vectors-negative300.bin\", \n",
    "        binary=True)\n",
    "    model.save_word2vec_format(\n",
    "        r\"C:\\Users\\Kashish\\Desktop\\GU SEM 7 PROJECT PROPOSAL\\Medical-Chatbot-master\\Medbot_Words.bin\",\n",
    "        binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93afe7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(r\"C:\\Users\\Kashish\\Desktop\\GU SEM 7 PROJECT PROPOSAL\\Medical-Chatbot-master\\data.pickle\",'rb',encoding=\"UTF-8\") as f:\n",
    "        word, labels, train, output=pickle.load(f)\n",
    "    \n",
    "except:    \n",
    "    words=[]\n",
    "    labels=[]\n",
    "    docs_x=[]\n",
    "    docs_y=[]\n",
    "    trains=[]\n",
    "    outputs=[]\n",
    "    missing=[]\n",
    "\n",
    "\n",
    "    for intent in data['intents']:\n",
    "            for code in intent['code']:\n",
    "                line=code.strip()\n",
    "\n",
    "                tokenizer = RegexpTokenizer(r'\\w+')\n",
    "                find=tokenizer.tokenize(line)\n",
    "                words.extend(find)\n",
    "                set=[]\n",
    "                for sim in find:\n",
    "                    if len(sim)>3:\n",
    "                        setting=[]\n",
    "                        try:\n",
    "                            similar=model.most_similar(positive=[sim.lower()], topn = 5)\n",
    "                            added=[i for i,j in similar]    \n",
    "                            for w in added:\n",
    "                                        \n",
    "                                        w=w.split(\",\")\n",
    "                                        setting.extend(w)\n",
    "\n",
    "                        except KeyError:\n",
    "                            missing.extend(sim)\n",
    "                        \n",
    "                        set.extend(setting)\n",
    "                find.extend(set)\n",
    "                words.extend(find)\n",
    "                docs_x.append(find)\n",
    "                docs_y.append(intent['tag'])\n",
    "                   \n",
    "            if(intent['tag'] not in labels):\n",
    "                labels.append(intent['tag'])\n",
    "\n",
    "    words=[(w.lower()) for w in words]\n",
    "    words=sorted(words)\n",
    "    word=[]\n",
    "    for w in words:\n",
    "        if w not in word:\n",
    "            word.append(w)\n",
    "    \n",
    "    labels=sorted(labels)\n",
    "    out_nul=[0 for _ in range(len(labels))]\n",
    "    for x,y in enumerate(docs_x):\n",
    "        bunch=[]\n",
    "        line=[w.lower() for w in y]                    \n",
    "        for w in word:\n",
    "            if w.lower() in line:\n",
    "                  bunch.append(1)\n",
    "            else:\n",
    "                  bunch.append(0)            \n",
    "        one_hot_row=out_nul[:]\n",
    "        one_hot_row[labels.index(docs_y[x])]=1\n",
    "        trains.append(bunch)\n",
    "        outputs.append(one_hot_row)\n",
    "\n",
    "    train=np.array(trains)\n",
    "    output=np.array(outputs)\n",
    "    with open(r\"C:\\Users\\Kashish\\Desktop\\GU SEM 7 PROJECT PROPOSAL\\Medical-Chatbot-master\\data.pickle\",'wb') as f:\n",
    "            pickle.dump((word,labels,train,output),f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f10ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_process(s,word):\n",
    "    count_a=0\n",
    "    count_b=0\n",
    "    count_c=0\n",
    "    out_a=0\n",
    "    out_b=0\n",
    "    out_c=0\n",
    "    flag=0\n",
    "    bag=[0 for _ in range(len(word))]\n",
    "    line=s.strip()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    find=tokenizer.tokenize(line)\n",
    "    find=[(w.lower()) for w in find]\n",
    "    for j in find:\n",
    "        for x,y in enumerate(word):\n",
    "            if(y==j):\n",
    "                bag[x]=1\n",
    "    for i in range(len(output)):\n",
    "        \n",
    "        c=bag*train[i]\n",
    "        d=np.sum(c)\n",
    "        flag=max(flag,d)\n",
    "        if d>count_a:\n",
    "            count_c=count_b\n",
    "            out_c=out_b\n",
    "            count_b=count_a\n",
    "            out_b=out_a  \n",
    "            count_a=d\n",
    "            out_a=i\n",
    "            \n",
    "        elif d>count_b:\n",
    "            count_c=count_b\n",
    "            out_c=out_b\n",
    "            count_b=d\n",
    "            out_b=i\n",
    "        elif d>count_c:\n",
    "            count_c=d\n",
    "            out_c=i    \n",
    "    return flag,out_a,out_b,out_c            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decb5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"dizziness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164dc916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk():\n",
    "    print(\" The Conversation Begins : Type Stop To Quit\\n\")\n",
    "    while True:\n",
    "        inp=input(\"User: \")\n",
    "        if inp.lower()==\"stop\":\n",
    "            break\n",
    "        flag,out_a,out_b,out_c=input_process(inp,word)\n",
    "        if flag != 0:\n",
    "            for intent in data[\"intents\"]:\n",
    "                for tg in intent[\"tag\"]:\n",
    "                    if docs_y[out_a]==tg.split(\",\"):\n",
    "                        print(\"Medbot: \"+random.choice(intent['response']))\n",
    "\n",
    "            if out_a != out_b and out_a>33:\n",
    "                    for intent in data[\"intents\"]:\n",
    "                        for tg in intent[\"tag\"]:\n",
    "                            if docs_y[out_b]==tg.split(\",\"):\n",
    "                                print(\"Medbot: \"+random.choice(intent['response']))\n",
    "\n",
    "            if(out_b!=out_c and out_a!=out_c and out_a>33):\n",
    "                for intent in data[\"intents\"]:\n",
    "                    for tg in intent[\"tag\"]:\n",
    "                        if docs_y[out_c]==tg.split(\",\"):\n",
    "                            print(\"Medbot: \"+random.choice(intent['response']))\n",
    "        elif flag == 0:\n",
    "            print(\"I didn't Understand What You Meant, Do not use shortforms and check for typos  \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afeeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Conversation Begins : Type Stop To Quit\n",
      "\n",
      "User: Hello there\n",
      "Medbot: Hello Human\n",
      "User: what do you do\n",
      "Medbot: I am A Medical Bot Which Listens To Your Symptoms  Tells You WIth Disease With You Show Higest Probablity Of Being Affected By.\n",
      "User: brittle bones\n",
      "Medbot: You Are Showing Symptoms Of bone cancer\n",
      "Medbot: You Are Showing Symptoms Of bone tumour\n",
      "Medbot: You Are Showing Symptoms Of hyperparathyroidism\n",
      "User: fever\n",
      "Medbot: You Are Showing Symptoms Of The Cold/Flu\n",
      "Medbot: You Are Showing Symptoms Of HIV AIDS\n",
      "Medbot: You Are Showing Symptoms Of Rheumatoid Arthritis\n",
      "User: swollen legs\n",
      "Medbot: You Are Showing Symptoms Of beriberi\n",
      "Medbot: You Are Showing Symptoms Of pregnancy\n",
      "Medbot: You Are Showing Symptoms Of HIV AIDS\n",
      "User: ears hurt\n",
      "Medbot: You Are Showing Symptoms Of The Allergies\n",
      "Medbot: You Are Showing Symptoms Of The Allergies\n",
      "Medbot: You Are Showing Symptoms Of Sinus Infection\n"
     ]
    }
   ],
   "source": [
    "talk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cda184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e887130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf4b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glad', 'pleased', 'ecstatic', 'overjoyed', 'thrilled', 'satisfied', 'proud', 'delighted', 'disappointed', 'excited']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "#load the pretrained model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    r\"C:\\Users\\Kashish\\Desktop\\GU SEM 7 PROJECT PROPOSAL\\Medical-Chatbot-master\\GoogleNews-vectors-negative300.bin\", \n",
    "    binary=True)\n",
    "\n",
    "#finding similar words from the model\n",
    "similar=model.most_similar(positive=['happy'], topn = 10)\n",
    "\n",
    "#converting similar words using the pretrained model\n",
    "sim=[i for i,j in similar]\n",
    "print(sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8c5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
